{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. **Métricas (Validación de los Modelos)**"
      ],
      "metadata": {
        "id": "ynn0S7ctdUbS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1 Reporte de Métricas"
      ],
      "metadata": {
        "id": "iwaigA8sevpz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1.1 Modelo A: BERT\n",
        "\n",
        "a. Iteración 1:\n",
        "\n",
        "Entrenamiento: Loss: 0.2651677090637386, accuracy: 0.90175\n",
        "\n",
        "Validación: Loss: 0.3484566710740328, accuracy: 0.892\n",
        "\n",
        "b. Iteración 2:\n",
        "\n",
        "Entrenamiento: Loss: 0.178699440728873, accuracy: 0.9460000000000001\n",
        "\n",
        "Validación: Loss: 0.40424482348561286, accuracy: 0.8935000000000001\n",
        "\n",
        "c. Iteración 3:\n",
        "\n",
        "Entrenamiento: Loss: 0.11829778066650033, accuracy: 0.971\n",
        "\n",
        "Validación: Loss: 0.4401103568077087, accuracy: 0.898\n",
        "\n",
        "d. Iteración 4:\n",
        "\n",
        "Entrenamiento: Loss: 0.07990703093074263, accuracy: 0.982625\n",
        "\n",
        "Validación: Loss: 0.49894495904445646, accuracy: 0.8965\n",
        "\n",
        "e. Iteración 5:\n",
        "\n",
        "Entrenamiento: Loss: 0.06776802394539118, accuracy: 0.9855\n",
        "\n",
        "Validación: Loss: 0.49894495904445646, accuracy: 0.8965"
      ],
      "metadata": {
        "id": "BwHxG1VvdTEs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1.2 Modelo B: Regresión Logística\n",
        "\n",
        "a. Accuracy: 81.23%\n",
        "\n",
        "b. Precision: 82.34%\n",
        "\n",
        "c. Recall: 87.42%\n",
        "\n",
        "d. F1 Score: 84.80%\n",
        "\n",
        "e. (Confusion Matrix):\n",
        " [[ 866  337]\n",
        " [ 226 1571]]\n",
        "\n",
        "Verdaderos positivos (TP): 866\n",
        "Falsos positivos (FP): 337\n",
        "Falsos negativos (FN): 226\n",
        "Verdaderos negativos (TN): 1571"
      ],
      "metadata": {
        "id": "8aWkr3tZeLbz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Comentarios**"
      ],
      "metadata": {
        "id": "lc5B3bf5fBu6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.1 Modelo BERT:\n",
        "\n",
        "a. Parece que el modelo BERT aprende bien del set de Train, aunque pudo presentarse un ligero overfitting, debido a que la precisión del set de Test (Validación) se estabiliza o disminuye en algunas iteraciones. Se podría realizar técnicas tales como: (regularización o ajuste de hiperparámetros) para optimizar aún más el rendimiento del modelo en el set de Test.\n",
        "\n",
        "b. Se obtuvo una precisión cerca al 90% lo que se puede considerar muy buena para tareas de clasificación de sentimientos.\n",
        "\n",
        "c. Para BERT se utilizaron 12 mil Reviews."
      ],
      "metadata": {
        "id": "Q99sKHPofJhQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2 Modelo Regresión Logística:\n",
        "\n",
        " a. El modelo muestra un rendimiento sólido en la clasificación de reseñas positivas y negativas, con un buen equilibrio entre Precisión y Recall.\n",
        "\n",
        " b. Es importante tener en cuenta que el modelo se ha entrenado y evaluado en un conjunto de datos balanceado, lo que significa que hay una cantidad igual de reseñas positivas y negativas. Esto puede ser beneficioso para evitar el sesgo del modelo hacia la clase mayoritaria y mejorar su capacidad para clasificar ambas clases de manera equilibrada. El modelo ha demostrado ser efectivo para clasificar reseñas en un conjunto de datos balanceado.\n",
        "\n",
        " c. Para Regresión Logística se utilizaron 15 mil Reviews."
      ],
      "metadata": {
        "id": "QaKW3Afcga5U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Conclusiones**"
      ],
      "metadata": {
        "id": "3eD2V4GlfGYN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. Como se puede ver en los resultados, BERT tiende a tener un rendimiento superior en términos de Accuracy en comparación con la Regresión Logística. Esto sugiere que BERT es mejor para clasificar reviews con mayor precisión y recuperar más reviews relevantes.\n",
        "\n",
        "b. BERT ha demostrado ser altamente efectivo, pero es un modelo robusto, que requiere mucha más exigencia computacional, y los entrenamientos e iteraciones tienden a requerir de un tiempo considerable, obviamente dependiendo del número de datos.\n",
        "\n",
        "c. La Regresión Logística es un modelo más simple y interpretable en comparación con BERT. Si la simplicidad es una prioridad y no se requiere un alto nivel de complejidad en el modelo, la Regresión Logística puede ser una elección sólida.\n",
        "\n",
        "d. Entrenar y utilizar un modelo de Regresión Logística generalmente requiere menos recursos computacionales en comparación con BERT."
      ],
      "metadata": {
        "id": "Dj26kX_1hZbL"
      }
    }
  ]
}